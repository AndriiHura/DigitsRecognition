{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image_array, num_of_digits):\n",
    "    \"\"\"Function splits the whole image into several images - 1 image for each digit\n",
    "       Takes: image_array - (1, 28, 28*num_of_digits, 1)\n",
    "       returns (num_of_images, 28, 28, 1) array\"\"\"\n",
    "    \n",
    "    new_array = image_array.copy().reshape(num_of_digits, 28, 28, 1)\n",
    "    for im in range(num_of_digits):\n",
    "        new_array[im][:,:,0] = image_array[0][:,28*im:28*(im+1), 0]# separating imput image into N images\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(example_images):\n",
    "    \"\"\" Function to get 1-digit images from sample dataset \"\"\"\n",
    "    images_array = np.zeros((40, 28, 28, 1))\n",
    "    i = 0\n",
    "    for image in example_images:\n",
    "        path = \"images/\"+image\n",
    "        # Openning image\n",
    "        input_image = Image.open(path)\n",
    "        # Converting it into numpy array, each value is in range (0, 255)\n",
    "        image_array = np.array(input_image, dtype = 'float32')\n",
    "        # Normalizing image\n",
    "        image_array = image_array / 255.\n",
    "        image_shape = image_array.shape\n",
    "        if(image_shape[0] > image_shape[1]): # Image is looks like column of numbers\n",
    "            image_array = np.rot90(image_array)\n",
    "            image_shape = image_array.shape\n",
    "        # Reshaping from (28, 28*num_digits) to (1, 28, 28*num_digits,1)\n",
    "        image_array = image_array.reshape(1, 28, image_shape[1],1)\n",
    "        num_of_digits = image_shape[1] // 28\n",
    "        # Reshaping from (1,28, 28*num_digits,1) to (num_digits, 28, 28,1)\n",
    "        splitted_images = split_image(image_array, num_of_digits)\n",
    "        images_array[i:i+4, :, :, :] = splitted_images\n",
    "        i += 4\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = os.listdir(\"images\")\n",
    "\n",
    "X_train = get_all_images(example_images)\n",
    "X_train = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for example images\n",
    "Y_train = np.array(  [4, 1, 4, 6,   \n",
    "                      2, 9, 7, 8,   \n",
    "                      3, 1, 6, 1,   \n",
    "                      2, 7, 9, 6,  \n",
    "                      8, 1, 2, 9,  \n",
    "                      6, 5, 2, 8,  \n",
    "                      2, 1, 7, 6,\n",
    "                      2, 4, 0, 7,\n",
    "                      6, 8, 5, 1,\n",
    "                      4, 7, 7, 0\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5, :, :, 0])\n",
    "print(Y_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model(still same architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Image Generator. I have got only 40 images(from example dataset), and I am going to increase that number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        #featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False   # randomly flip images\n",
    ")  \n",
    "\n",
    "\n",
    "#datagen = datagen.flow(X_train,Y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Creating new array for images - it contains 10200 objects more\n",
    "new_X = np.zeros((10240, 28, 28, 1))\n",
    "new_X[:40, :, :, :] = X_train\n",
    "\n",
    "new_Y = np.zeros((10240, 10))\n",
    "new_Y[:40, :] = Y_train\n",
    "\n",
    "# Inserting freshly generated images into new datasets\n",
    "for batch in datagen.flow(X_train, Y_train, batch_size=1):\n",
    "    new_X[41+i, :, :, :] = batch[0]\n",
    "    new_Y[41+i, :] = batch[1]\n",
    "    i += 1\n",
    "    if i > 10198:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(new_Y[10239])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159b35be308>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_X[10239, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(new_X, new_Y, test_size = 0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6963 samples, validate on 1741 samples\n",
      "Epoch 1/50\n",
      "6963/6963 [==============================] - 40s 6ms/step - loss: 0.9826 - accuracy: 0.6612 - val_loss: 0.1085 - val_accuracy: 0.9673\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10847, saving model to model_weights_2attempt.h5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndriiHura\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6963/6963 [==============================] - 39s 6ms/step - loss: 0.1336 - accuracy: 0.9575 - val_loss: 0.0840 - val_accuracy: 0.9724\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10847 to 0.08396, saving model to model_weights_2attempt.h5\n",
      "Epoch 3/50\n",
      "6963/6963 [==============================] - 39s 6ms/step - loss: 0.0681 - accuracy: 0.9789 - val_loss: 0.0135 - val_accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08396 to 0.01345, saving model to model_weights_2attempt.h5\n",
      "Epoch 4/50\n",
      "6963/6963 [==============================] - 38s 5ms/step - loss: 0.0442 - accuracy: 0.9843 - val_loss: 0.0198 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01345\n",
      "Epoch 5/50\n",
      "6963/6963 [==============================] - 39s 6ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01345 to 0.00772, saving model to model_weights_2attempt.h5\n",
      "Epoch 6/50\n",
      "6963/6963 [==============================] - 40s 6ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.0029 - val_accuracy: 0.9989s - loss: 0.0213 - accuracy: 0.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00772 to 0.00295, saving model to model_weights_2attempt.h5\n",
      "Epoch 7/50\n",
      "6963/6963 [==============================] - 40s 6ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00295\n",
      "Epoch 8/50\n",
      "6963/6963 [==============================] - 41s 6ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0093 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00295\n",
      "Epoch 9/50\n",
      "6963/6963 [==============================] - 41s 6ms/step - loss: 0.0316 - accuracy: 0.9907 - val_loss: 0.0074 - val_accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00295\n",
      "Epoch 10/50\n",
      "6963/6963 [==============================] - 40s 6ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x159d243db08>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 50, verbose = 1, validation_split=0.2\n",
    "                              , \n",
    "          callbacks=[learning_rate_reduction, \n",
    "        ModelCheckpoint('model_weights_2attempt.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "                    early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 1, ..., 4, 7, 2], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " ...]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = [np.argmax(y) for y in Y_test]\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993489583333334\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions, actual))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
