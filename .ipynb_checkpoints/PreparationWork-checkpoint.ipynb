{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_weights_50epochs.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading some MNIST data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(\"label\", axis=1)\n",
    "\n",
    "# Normalization\n",
    "test = test/255.\n",
    "X_train = X_train/255.\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, 28, 28, 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and accuracy estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated accuracy: 0.9954047619047619\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "pred_classes = np.argmax(predictions,axis = 1) \n",
    "print(\"Estimated accuracy: {}\".format(accuracy_score(pred_classes, Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAAAcCAAAAACcvWS2AAAB9UlEQVR4nGNgGAUDBmyXbFGngjFMqFzzp69tsaoTrY8U+P+AgGHyc8QIWsiCwlNZzMZwCZsy68z1y/qf/sRvFmsqMz5pZlNnWf4XKBaKrhRkePgRm2KF0ucuDPfw28cQwo1PVilbjoGBQRjZQq5lcmuDsXqQYSkDgwIhCzWEzzrjljXPZ727+tp35DhknmPQeY7hIi4dhCzkDF2AR1a9kPVA9dnvKImm03VOjwH2KCTGwuiNX3BL8hUxX5nxl4EB2cKC+HVVDAY4fSgg8P4DPvuMf+F0KgMDQ7DQ976/DAwMSKk0pGpvzn9u5SfvcGhRxO9BPvcePLIs9gx7XRyFn6w+A/ehzcQzib8Z9JlwOlMev4Vxy3/hkdXkZrCPkmRTKtODWaix8F7UdwYGfdxRiN+Hdo/u43OOMgPDt4kJRS8ZXWBBWs/Hd5uBgYGBoaIi8AhWPQoM+Iw01wpkYGBgYOhkmH8Ii7Qgw5uybwxfjwdwwiyMhFC3eOVxhAyT7M+neCzsZmBgYGAI9yh/hVX6P8O3bwwMDJoMV1DLUnHBe7hiQprt/n88FhIALxjknNkFE9Xf7EYtSzUYbmJTbtjMwMDAoLGFgaHwNnkWHg7ly8hgYPje/w3VQnXsFp73Ic8aBPhaF63C8+7cpjeUGjQKRsEoGJIAAM8XhtMdW+TJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=112x28 at 0x26DCACDE308>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_1 = Image.open(\"images/00000.png\")\n",
    "display(test_image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test_image_1 = np.array(test_image_1, dtype = 'float32').reshape(1,28,112,1)\n",
    "array_test_image_1 = array_test_image_1 / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 112)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_image_1,dtype = 'float32').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 112, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test_image_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26dcada7b48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(array_test_image_1[0][:,:28,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting splitted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26dcb338808>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(array_test_image_1[0][:,28:56,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(array_test_image_1[:, :,28:56,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test_image_1[:, :,:28,].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to generate sample like data(composed from mnist numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1x4_image(num_of_images, num_of_digits):\n",
    "    list_of_images = []\n",
    "    actual_classes = []\n",
    "    for im in range(num_of_images):\n",
    "        rand_indexes = np.random.randint(28000, size=(num_of_digits))\n",
    "        long_image  = X_train[rand_indexes[0]][:,:,0]\n",
    "        image_labels =[ Y_train[index] for index in rand_indexes]\n",
    "        for ind in range(1,num_of_digits):\n",
    "            long_image  = np.concatenate((long_image, X_train[rand_indexes[ind]][:,:,0]), axis=1)\n",
    "        actual_classes.append(image_labels)\n",
    "        list_of_images.append(long_image)\n",
    "    return np.array(list_of_images), actual_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to create some test data, then run this cell\n",
    "# Pass to the function number of test images, and amount of numbers each image will contain\n",
    "gen_images, gen_images_labels = generate_1x4_image(20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 28, 112)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving generated images to the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in range(20):\n",
    "    save_image_name = \"\".join(list(map(lambda x: str(x), gen_images_labels[im])))\n",
    "    save_image = (((gen_images[im] - gen_images[im].min()) /\\\n",
    "                   (gen_images[im].max() - gen_images[im].min())) * 255.9).astype(np.uint8)\n",
    "    save_image = Image.fromarray(save_image)\n",
    "    save_path = \"GeneratedTestImages/\"+save_image_name+\".png\"\n",
    "    save_image.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to split whole image, and to predict whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(image_array, num_of_digits):\n",
    "    \"\"\"Function splits the whole image into several images - 1 image for each digit\n",
    "       Takes: image_array - (1, 28, 28*num_of_digits, 1)\n",
    "       returns (num_of_images, 28, 28, 1) array\"\"\"\n",
    "    \n",
    "    new_array = image_array.copy().reshape(num_of_digits, 28, 28, 1)\n",
    "    for im in range(num_of_digits):\n",
    "        new_array[im][:,:,0] = image_array[0][:,28*im:28*(im+1), 0]# separating imput image into N images\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def predict_full_image(image_path):\n",
    "    \"\"\"Function predicts all numbers on input image, in order from left to right\"\"\"\n",
    "    \n",
    "    # Openning image\n",
    "    input_image = Image.open(image_path)\n",
    "    # Converting it into numpy array, each value is in range (0, 255)\n",
    "    image_array = np.array(input_image, dtype = 'float32')\n",
    "    # Normalizing image\n",
    "    image_array = image_array / 255.\n",
    "    image_shape = image_array.shape\n",
    "    if(image_shape[0] > image_shape[1]): # Image is looks like column of numbers\n",
    "        image_array = np.rot90(image_array)\n",
    "        image_shape = image_array.shape\n",
    "    # Reshaping from (28, 28*num_digits) to (1, 28, 28*num_digits,1)\n",
    "    image_array = image_array.reshape(1, 28, image_shape[1],1)\n",
    "    num_of_digits = image_shape[1] // 28\n",
    "    # Reshaping from (1,28, 28*num_digits,1) to (num_digits, 28, 28,1)\n",
    "    splitted_images = split_image(image_array, num_of_digits)\n",
    "    # Predicting result\n",
    "    answer = model.predict_classes(splitted_images)\n",
    "    answer = \"\".join(str(x) for x in answer)\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4973'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_full_image(\"C:/Users/AndriiHura/Desktop/4973.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4770'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_full_image(\"images/00009.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = os.listdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4146\n",
      "2978\n",
      "3161\n",
      "2759\n",
      "8123\n",
      "6528\n",
      "2276\n",
      "2407\n",
      "6351\n",
      "4770\n"
     ]
    }
   ],
   "source": [
    "for image in example_images:\n",
    "    path = \"images/\"+image\n",
    "    print(predict_full_image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen_images = os.listdir(\"GeneratedTestImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actulal label: 0191.png, Predicted label: 0191\n",
      "Actulal label: 0259.png, Predicted label: 0259\n",
      "Actulal label: 0638.png, Predicted label: 0638\n",
      "Actulal label: 0861.png, Predicted label: 0861\n",
      "Actulal label: 1022.png, Predicted label: 1022\n",
      "Actulal label: 1360.png, Predicted label: 1360\n",
      "Actulal label: 1461.png, Predicted label: 1461\n",
      "Actulal label: 1621.png, Predicted label: 1621\n",
      "Actulal label: 1877.png, Predicted label: 1877\n",
      "Actulal label: 2207.png, Predicted label: 2207\n",
      "Actulal label: 3070.png, Predicted label: 3070\n",
      "Actulal label: 3642.png, Predicted label: 3642\n",
      "Actulal label: 4625.png, Predicted label: 4625\n",
      "Actulal label: 4667.png, Predicted label: 4667\n",
      "Actulal label: 4720.png, Predicted label: 4720\n",
      "Actulal label: 4835.png, Predicted label: 4835\n",
      "Actulal label: 5005.png, Predicted label: 5005\n",
      "Actulal label: 5356.png, Predicted label: 5356\n",
      "Actulal label: 5521.png, Predicted label: 5521\n",
      "Actulal label: 5525.png, Predicted label: 5525\n",
      "Actulal label: 5902.png, Predicted label: 5902\n",
      "Actulal label: 6131.png, Predicted label: 6131\n",
      "Actulal label: 6452.png, Predicted label: 6452\n",
      "Actulal label: 6640.png, Predicted label: 6640\n",
      "Actulal label: 6671.png, Predicted label: 6671\n",
      "Actulal label: 7107.png, Predicted label: 7107\n",
      "Actulal label: 7261.png, Predicted label: 7261\n",
      "Actulal label: 7831.png, Predicted label: 7831\n",
      "Actulal label: 7879.png, Predicted label: 7879\n",
      "Actulal label: 7942.png, Predicted label: 7992\n",
      "Actulal label: 8177.png, Predicted label: 8177\n",
      "Actulal label: 8431.png, Predicted label: 8431\n",
      "Actulal label: 8743.png, Predicted label: 8743\n",
      "Actulal label: 8885.png, Predicted label: 8885\n",
      "Actulal label: 8934.png, Predicted label: 8934\n",
      "Actulal label: 9167.png, Predicted label: 9167\n",
      "Actulal label: 9751.png, Predicted label: 9751\n",
      "Actulal label: 9771.png, Predicted label: 9771\n",
      "Actulal label: 9795.png, Predicted label: 9795\n",
      "Actulal label: 9831.png, Predicted label: 9831\n"
     ]
    }
   ],
   "source": [
    "for image in test_gen_images:\n",
    "    path = \"GeneratedTestImages/\"+image\n",
    "    predicted = predict_full_image(path)\n",
    "    predicted = \"\".join(list(map(lambda x: str(x), predicted)))\n",
    "    print(\"Actulal label: {}, Predicted label: {}\".format(image,predicted ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/00001.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2978'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_full_image(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/AndriiHura/FaiflyTestTask/images/00000.png\n"
     ]
    }
   ],
   "source": [
    "Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6528'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_full_image(askopenfilename())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
